import requests
import pandas as pd
import time
import os
from datetime import datetime

# API í‚¤ (ì¸ì½”ë”©ëœ ìƒíƒœ ê·¸ëŒ€ë¡œ)
API_KEY = "MNUICj9LF0yMX9b9cMQiBVz62JWYaqaGxBOIATmwvQgzkfdHQjzCouGaBLIzyg6MYGQOHqefVCRf3E23XoqVGA%3D%3D"

# í˜„ì¬ íŒŒì¼ ìœ„ì¹˜ ê¸°ì¤€ ê²½ë¡œ ì„¤ì •
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# ê²½ë¡œ ì„¤ì •
STATION_FILE = os.path.join(BASE_DIR, "ëŒ€ì „_ì¸¡ì •ì†Œ_ëª©ë¡.xlsx")
CSV_FILE = os.path.join(BASE_DIR, "ëŒ€ì „_ë¯¸ì„¸ë¨¼ì§€_ë°ì´í„°.csv")
XLSX_FILE = os.path.join(BASE_DIR, "ëŒ€ì „_ë¯¸ì„¸ë¨¼ì§€_ë°ì´í„°.xlsx")
JSON_FILE = os.path.join(BASE_DIR, "ëŒ€ì „_ë¯¸ì„¸ë¨¼ì§€_ë°ì´í„°.json")  # âœ… ì¶”ê°€

# ì¸¡ì •ì†Œ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
station_df = pd.read_excel(STATION_FILE)
daejeon_stations = station_df["stationName"].dropna().unique().tolist()

def fetch_dust_data():
    results = []
    for station in daejeon_stations:
        url = (
            f"http://apis.data.go.kr/B552584/ArpltnInforInqireSvc/"
            f"getMsrstnAcctoRltmMesureDnsty"
            f"?serviceKey={API_KEY}"
            f"&returnType=json"
            f"&numOfRows=1"
            f"&pageNo=1"
            f"&stationName={station}"
            f"&dataTerm=DAILY"
            f"&ver=1.0"
        )
        try:
            res = requests.get(url, timeout=5)
            if res.status_code == 200:
                body = res.json().get("response", {}).get("body", {})
                items = body.get("items", [])
                if items:
                    item = items[0]
                    results.append({
                        "ìˆ˜ì§‘ì‹œê°": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        "ì¸¡ì •ì‹œê°": item.get("dataTime", ""),
                        "ì¸¡ì •ì†Œ": station,
                        "PM10": item.get("pm10Value", ""),
                        "PM2.5": item.get("pm25Value", ""),
                        "í†µí•©ì§€ìˆ˜": item.get("khaiValue", ""),
                        "ì˜¤ì¡´": item.get("o3Value", ""),
                        "ì´ì‚°í™”ì§ˆì†Œ": item.get("no2Value", ""),
                        "ì¼ì‚°í™”íƒ„ì†Œ": item.get("coValue", ""),
                        "ì•„í™©ì‚°ê°€ìŠ¤": item.get("so2Value", "")
                    })
                else:
                    print(f"âš ï¸ {station} â†’ ì¸¡ì • ë°ì´í„° ì—†ìŒ (items ë¹„ì–´ ìˆìŒ)")
            else:
                print(f"âŒ {station} ìš”ì²­ ì‹¤íŒ¨: {res.status_code}")
        except Exception as e:
            print(f"âš ï¸ {station} ì˜¤ë¥˜: {e}")
        time.sleep(0.2)
    return pd.DataFrame(results)

def append_and_save(new_df):
    if new_df.empty:
        print("âš ï¸ ìƒˆë¡œ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    if os.path.exists(CSV_FILE):
        existing_df = pd.read_csv(CSV_FILE)
        combined_df = pd.concat([existing_df, new_df], ignore_index=True)
    else:
        combined_df = new_df

    # ì €ì¥ (CSV, Excel, JSON)
    combined_df.to_csv(CSV_FILE, index=False, encoding="utf-8-sig")
    combined_df.to_excel(XLSX_FILE, index=False)
    combined_df.to_json(JSON_FILE, orient="records", force_ascii=False, indent=2)  # âœ… JSON ì €ì¥

    print(f"âœ… ì €ì¥ ì™„ë£Œ ({len(new_df)}ê°œ ì¶”ê°€ë¨) - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

# ìˆ˜ì§‘ ë£¨í”„ ì‹œì‘
while True:
    print("ğŸ“¡ ë¯¸ì„¸ë¨¼ì§€ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
    new_data = fetch_dust_data()
    append_and_save(new_data)

    print("ğŸ•’ ë‹¤ìŒ ìˆ˜ì§‘ê¹Œì§€ 1ì‹œê°„ ëŒ€ê¸°...\n")
    time.sleep(60 * 60)
